# Foggy Railway Segmentation Project

## Overview

This project focuses on segmenting railway tracks in foggy conditions using the BiSeNetV2 model. It covers preprocessing, pseudo-labeling, targeted fine-tuning, and result analysis.

---

## ğŸ“ Project Structure

```rail_marking/
â”œâ”€â”€ cfg/ # Model configuration files
â”œâ”€â”€ data/                   # Input datasets (clear/fog/hard_example)
â”œâ”€â”€ model/                  # Trained checkpoints (.pth)
â”œâ”€â”€ my_scripts/ # Pseudo-labels, fine-tuning, comparison tools
â”œâ”€â”€ notebooks/ # Evaluation notebooks
â”œâ”€â”€ output/ # Inference results (before/after)
â”œâ”€â”€ rail_marking/ # Core model, training, data loaders
â”œâ”€â”€ scripts/ # Main training/inference scripts
â”œâ”€â”€ tests/ # Unit tests
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ environment.yml
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ Railtrack Segmentation Project Report.pdf
```

---

ğŸ“‚ External Resources (Data & Outputs)
Due to size constraints, datasets, model checkpoints and inference results are hosted externally.

ğŸ‘‰ Access all project resources here (https://drive.google.com/drive/folders/13orpV4tsqUL9mubSU6Mx9xsqm8MOvBhg?usp=drive_link)

Contents:
/data/clear/, /data/fog/, /data/hard_example/ â€“ Input datasets and pseudo-labels

/model_checkpoints/ â€“ All .pth files (pretrained and fine-tuned)

/output/ â€“ Inference results and visual comparisons

---

## ğŸ“‚ Downloaded Resources â€“ Where to Place Them

After downloading the project files from Google Drive, place the folders **in the root directory of the project**, at the same level as `README.md`.

---

## âš™ï¸ Setup Instructions

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---
1. Baseline Inference on Foggy Images

Evaluate the pretrained model on foggy inputs.

ğŸ“ Output: output/fog_results/

2. Generate Pseudo-Labels for Clear Images

Create segmentation masks using the pretrained model.

ğŸ“ Output: data/clear/masks/

3. Fine-Tune on Pseudo-Labeled Clear Images

Train the model on clear-weather images with generated masks.

ğŸ“ Output model: model/bisenetv2_finetuned.pth

4. Evaluate Fine-Tuned Model

Run inference again using the newly fine-tuned model.

ğŸ“ Output: output/fog_results_finetuned/

5. Draw Manual Mask for Hard Example

Use GUI to manually label the false-positive fog image.

ğŸ“ Output: data/hard_example/masks/
ğŸ’¡ Duplicate the image and mask to simulate a batch (needed for BatchNorm).

6. Fine-Tune Only on the Hard Example

Train the model specifically to correct the hard example.

ğŸ“ Output model: model/bisenetv2_finetuned_hard_example.pth

7. Compare Before/After on Hard Example

Generate side-by-side visualizations for evaluation.

ğŸ“ Output: output/hard_example_comparison/

8. Fine-Tune on Combined Dataset

Train using both clear and hard example data for better generalization.

ğŸ“ Output model: model/bisenetv2_finetuned_combined.pth

9. Compare Before/After Combined Fine-Tuning

Final visual evaluation of combined model.

ğŸ“ Output: output/hard_example_comparison_combined/
---

## ğŸ“Š Evaluation Methods

- Visual overlays & inspection
- Entropy, skewness, Bhattacharyya distance
- Tracking performance on hard examples

---

## ğŸ¯ Evaluation Access

All results and models are fully reproducible.  
Please refer to [`fog_segmentation_evaluation.ipynb`](notebooks/fog_segmentation_evaluation.ipynb) for step-by-step visualization and comparison.

For further questions or full-resolution visual results, feel free to reach out.

---

## ğŸ“ Notes

- See `report.pdf` for detailed write-up
- Pseudo-labeling and correction were essential for fog adaptation

---

### ğŸ”— Based on
Original baseline from https://github.com/xmba15/rail_marking (BiSeNetV2)
